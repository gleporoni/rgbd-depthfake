# reproducibility
seed: 42

cuda_device: '0'

# pl_trainer
pl_trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: 'gpu'
  # devices: [6]
  max_epochs: 30
  # auto_scale_batch_size: 'power'
  accumulate_grad_batches: 6
  # gradient_clip_val: 10.0
  # val_check_interval: 1.0  # you can specify an int "n" here => validation every "n" steps
  # uncomment the lines below for training with mixed precision
  # precision: 16
  # amp_level: O2

# early stopping callback
# "early_stopping_callback: null" will disable early stopping
# early_stopping_callback:
#   _target_: pytorch_lightning.callbacks.EarlyStopping
#   monitor: val_loss
#   mode: min
#   patience: 50

# model_checkpoint_callback
# "model_checkpoint_callback: null" will disable model checkpointing
model_checkpoint_callback_loss:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  monitor: val_loss
  mode: min
  verbose: True
  save_top_k: 1
  dirpath: experiments/loss/${model.model_name}

model_checkpoint_callback_acc:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  monitor: val_accuracy
  mode: max
  verbose: True
  save_top_k: 1
  dirpath: experiments/accuracy/${model.model_name}

path_last: experiments/last/${model.model_name}

experiment:
  pretrain: False
  checkpoint_file: experiments/depth_double_mobilenet/2023-04-29/10-08-54/experiments/accuracy/depth_double_mobilenet/epoch=1-step=3134.ckpt